{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 3: Multiple Data Scientists Working on Multiple ML Models\n",
    "\n",
    "### MLflow Setup\n",
    "\n",
    "- **Tracking server**: Yes, remote server (GCP VM).\n",
    "- **Backend store**: PostgreSQL database.\n",
    "- **Artifacts store**: Google Cloud Storage (GCS) bucket.\n",
    "\n",
    "The experiments can be explored by accessing the remote server.\n",
    "\n",
    "The example uses GCP to host a remote server. In order to run the example, you'll need a GCP account. Follow the steps below to create a new GCP account, set up the necessary infrastructure, and launch the tracking server.\n",
    "\n",
    "### Steps to Set Up MLflow on GCP\n",
    "\n",
    "1. **Create a GCP Account**:\n",
    "   - Go to the [Google Cloud Console](https://console.cloud.google.com/).\n",
    "   - Follow the instructions to create a new GCP account and set up billing.\n",
    "\n",
    "2. **Create a GCP VM Instance**:\n",
    "   - Navigate to the Compute Engine section in the Google Cloud Console.\n",
    "   - Create a new VM instance:\n",
    "     - Choose a name for your instance.\n",
    "     - Select a region and zone.\n",
    "     - Choose a machine type (e.g., n1-standard-1).\n",
    "     - Configure boot disk (e.g., Ubuntu 20.04 LTS).\n",
    "   - Allow HTTP/HTTPS traffic in the \"Firewall\" section.\n",
    "   - Create and start the instance.\n",
    "\n",
    "3. **Set Up PostgreSQL on GCP**:\n",
    "   - Optionally, you can use Cloud SQL to set up a managed PostgreSQL instance.\n",
    "   - Alternatively, install PostgreSQL on your VM:\n",
    "     ```sh\n",
    "     sudo apt update\n",
    "     sudo apt install -y postgresql postgresql-contrib\n",
    "     sudo -i -u postgres\n",
    "     createuser --interactive\n",
    "     createdb mlflow\n",
    "     ```\n",
    "\n",
    "4. **Create a GCS Bucket**:\n",
    "   - Go to the Storage section in the Google Cloud Console.\n",
    "   - Create a new bucket for storing MLflow artifacts.\n",
    "\n",
    "5. **SSH into Your VM**:\n",
    "   ```sh\n",
    "   gcloud compute ssh <your-vm-instance-name>\n",
    "\n",
    "6. **Install MLflow and PostgreSQL on Your VM:**\n",
    "   - sudo apt update\n",
    "   - sudo apt install -y python3-pip\n",
    "   - pip3 install mlflow psycopg2-binary\n",
    "\n",
    "7. **Start MLflow server:**\n",
    "   - mlflow server \\\n",
    "    --backend-store-uri postgresql://<username>:<password>@localhost/mlflow \\\n",
    "    --default-artifact-root gs://<your-gcs-bucket> \\\n",
    "    --host 0.0.0.0 --port 5000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import os\n",
    "\n",
    "os.environ[\"AWS_PROFILE\"] = \"\" # fill in with your AWS profile. More info: https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/setup.html#setup-credentials\n",
    "\n",
    "TRACKING_SERVER_HOST = \"\" # fill in with the public DNS of the EC2 instance\n",
    "mlflow.set_tracking_uri(f\"http://{TRACKING_SERVER_HOST}:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"tracking URI: '{mlflow.get_tracking_uri()}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.search_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mlflow.set_experiment(\"my-experiment-1\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "\n",
    "    X, y = load_iris(return_X_y=True)\n",
    "\n",
    "    params = {\"C\": 0.1, \"random_state\": 42}\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    lr = LogisticRegression(**params).fit(X, y)\n",
    "    y_pred = lr.predict(X)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy_score(y, y_pred))\n",
    "\n",
    "    mlflow.sklearn.log_model(lr, artifact_path=\"models\")\n",
    "    print(f\"default artifacts URI: '{mlflow.get_artifact_uri()}'\")\n",
    "    \n",
    "mlflow.search_experiments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interacting with the model registry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "\n",
    "client = MlflowClient(f\"http://{TRACKING_SERVER_HOST}:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.list_registered_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = client.list_run_infos(experiment_id='1')[0].run_id\n",
    "mlflow.register_model(\n",
    "    model_uri=f\"runs:/{run_id}/models\",\n",
    "    name='iris-classifier'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp-tracking-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
