{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***`Homework`***\n",
    "---\n",
    "\n",
    "The goal of this homework is to train a simple model for predicting the duration of a ride - similar to what we did in this module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan23 = pd.read_parquet('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-01.parquet')\n",
    "feb23 = pd.read_parquet('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-02.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Q1. Downloading the data***\n",
    "---\n",
    "\n",
    "We'll use the same NYC taxi dataset, but instead of \"Green Taxi Trip Records\", we'll use \"Yellow Taxi Trip Records\".\n",
    "\n",
    "Download the data for January and February 2023.\n",
    "\n",
    "Read the data for January. How many columns are there?\n",
    "\n",
    "- 16\n",
    "- 17\n",
    "- 18\n",
    "- 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 19\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of columns: {jan23.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Computing duration\n",
    "---\n",
    "\n",
    "Now let's compute the duration variable. It should contain the duration of a ride in minutes.\n",
    "\n",
    "What's the standard deviation of the trips duration in January?\n",
    "\n",
    "- 32.59\n",
    "- 42.59\n",
    "- 52.59\n",
    "- 62.59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3.066766e+06\n",
       "mean     1.566900e+01\n",
       "std      4.259435e+01\n",
       "min     -2.920000e+01\n",
       "25%      7.116667e+00\n",
       "50%      1.151667e+01\n",
       "75%      1.830000e+01\n",
       "max      1.002918e+04\n",
       "Name: duration_minutes, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jan23['duration_minutes'] = (jan23['tpep_dropoff_datetime'] - jan23['tpep_pickup_datetime']).dt.total_seconds() / 60\n",
    "jan23['duration_minutes'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do same to validation data set (feb23)\n",
    "feb23['duration_minutes'] = (feb23['tpep_dropoff_datetime'] - feb23['tpep_pickup_datetime']).dt.total_seconds() / 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Q3. Dropping outliers***\n",
    "---\n",
    "\n",
    "Next, we need to check the distribution of the duration variable. There are some outliers. Let's remove them and keep only the records where the duration was between 1 and 60 minutes (inclusive).\n",
    "\n",
    "What fraction of the records left after you dropped the outliers?\n",
    "\n",
    "- 90%\n",
    "- 92%\n",
    "- 95%\n",
    "- 98%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of trips that are between 1 and 60 minutes: 0.98\n"
     ]
    }
   ],
   "source": [
    "mask = (jan23['duration_minutes'] >= 1) & (jan23['duration_minutes'] <= 60)\n",
    "\n",
    "# Filter out trips that are less than 1 minute and more than 60 minutes\n",
    "jan23_clean = jan23[mask].copy()\n",
    "\n",
    "# fraction\n",
    "fraction = jan23_clean.shape[0] / jan23.shape[0]\n",
    "\n",
    "print(f\"Fraction of trips that are between 1 and 60 minutes: {fraction:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do same to validation data set (feb23)\n",
    "mask = (feb23['duration_minutes'] >= 1) & (feb23['duration_minutes'] <= 60)\n",
    "feb23_clean = feb23[mask].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Q4. One-hot encoding***\n",
    "---\n",
    "\n",
    "Let's apply one-hot encoding to the pickup and dropoff location IDs. We'll use only these two features for our model.\n",
    "\n",
    "Turn the dataframe into a list of dictionaries (remember to re-cast the ids to strings - otherwise it will label encode them)\n",
    "Fit a dictionary vectorizer\n",
    "Get a feature matrix from it\n",
    "What's the dimensionality of this matrix (number of columns)?\n",
    "\n",
    "- 2\n",
    "- 155\n",
    "- 345\n",
    "- 515\n",
    "- 715"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 515\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# filter columns:\n",
    "columns     = ['PULocationID', 'DOLocationID', 'duration_minutes']\n",
    "jan23_clean = jan23_clean[columns]\n",
    "feb23_clean = feb23_clean[columns]\n",
    "\n",
    "# cast to str\n",
    "jan23_clean['PULocationID'] = jan23_clean['PULocationID'].astype(str)\n",
    "jan23_clean['DOLocationID'] = jan23_clean['DOLocationID'].astype(str)\n",
    "\n",
    "feb23_clean['PULocationID'] = feb23_clean['PULocationID'].astype(str)\n",
    "feb23_clean['DOLocationID'] = feb23_clean['DOLocationID'].astype(str)\n",
    "\n",
    "# define train a. validation sets\n",
    "X_train, y_train = jan23_clean.drop(columns='duration_minutes'), jan23_clean['duration_minutes']\n",
    "X_test, y_test   = feb23_clean.drop(columns='duration_minutes'), feb23_clean['duration_minutes']\n",
    "\n",
    "# vectorize\n",
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "train_dict      = X_train.to_dict(orient='records')\n",
    "X_train_encoded = dv.fit_transform(train_dict)\n",
    "\n",
    "test_dict       = X_test.to_dict(orient='records')\n",
    "X_test_encoded  = dv.transform(test_dict)\n",
    "\n",
    "# n dimensions\n",
    "print(f\"Number of columns: {X_train_encoded.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_encoded[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Q5. Training a model***\n",
    "---\n",
    "\n",
    "Now let's use the feature matrix from the previous step to train a model.\n",
    "\n",
    "Train a plain linear regression model with default parameters\n",
    "Calculate the RMSE of the model on the training data\n",
    "What's the RMSE on train?\n",
    "\n",
    "- 3.64\n",
    "- 7.64\n",
    "- 11.64\n",
    "- 16.64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rmse = lambda y_true, y_pred: np.sqrt( mean_squared_error(y_true, y_pred) )\n",
    "\n",
    "# train model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_encoded, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred_train = model.predict(X_train_encoded)\n",
    "\n",
    "# evaluate\n",
    "rmse(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Q6. Evaluating the model***\n",
    "---\n",
    "\n",
    "Now let's apply this model to the validation dataset (February 2023).\n",
    "\n",
    "What's the RMSE on validation?\n",
    "\n",
    "- 3.81\n",
    "- 7.81\n",
    "- 11.81\n",
    "- 16.81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = model.predict(X_test_encoded)\n",
    "rmse(y_test, y_pred_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
